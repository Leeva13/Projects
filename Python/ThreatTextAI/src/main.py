import sys
import os
from train import train_model, predict_text
import pandas as pd
from transformers import BertTokenizer, BertForSequenceClassification
from torch.utils.data import DataLoader
import torch
from dataset import ThreatDataset
from sklearn.metrics import accuracy_score, f1_score

def evaluate_test_data():
    if not os.path.exists("models/best_model.pth"):
        print("\n‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞: –ú–æ–¥–µ–ª—å —â–µ –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–±–µ—Ä—ñ—Ç—å –æ–ø—Ü—ñ—é 1 –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.")
        return
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
    model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=4)
    model.load_state_dict(torch.load("models/best_model.pth", map_location=torch.device('cpu')))
    model.eval()
    model.to(torch.device('cpu'))  # –ü–µ—Ä–µ–º—ñ—â–∞—î–º–æ –Ω–∞ CPU –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    if not os.path.exists("data/test.csv"):
        print("\n‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª data/test.csv –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –°—Ç–≤–æ—Ä—ñ—Ç—å –π–æ–≥–æ –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'text' —ñ 'label'.")
        return

    test_dataset = ThreatDataset('data/test.csv', tokenizer=tokenizer)
    test_loader = DataLoader(test_dataset, batch_size=16)

    # –û—Ü—ñ–Ω–∫–∞
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for batch in test_loader:
            input_ids = batch['input_ids'].to(torch.device('cpu'))
            attention_mask = batch['attention_mask'].to(torch.device('cpu'))
            labels = batch['labels']
            outputs = model(input_ids, attention_mask=attention_mask)
            _, predicted = torch.max(outputs.logits, 1)
            all_preds.extend(predicted.numpy())
            all_labels.extend(labels.numpy())

    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='weighted')
    correct = sum(1 for p, l in zip(all_preds, all_labels) if p == l)
    total = len(all_labels)

    print("–î–µ—Ç–∞–ª—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å:")
    for i, (pred, label) in enumerate(zip(all_preds, all_labels)):
        print(f"–ü—Ä–∏–∫–ª–∞–¥ {i+1}: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ {pred} (—Å–ø—Ä–∞–≤–∂–Ω—î {label})")

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ {total} –ø—Ä–∏–∫–ª–∞–¥–∞—Ö:")
    print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ –≤–≥–∞–¥–∞–Ω–æ: {correct} ({accuracy*100:.2f}%)")
    print(f"üìà F1-Score: {f1:.4f}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–ø—É—Å–∫—É ThreatTextAI —á–µ—Ä–µ–∑ —Ç–µ—Ä–º—ñ–Ω–∞–ª."""
    print("–õ–∞—Å–∫–∞–≤–æ –ø—Ä–æ—Å–∏–º–æ –¥–æ ThreatTextAI!")
    print("–¶–µ–π –ø—Ä–æ—î–∫—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫—É—î —Ç–µ–∫—Å—Ç–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑–∞ —Ç–∏–ø–æ–º –∑–∞–≥—Ä–æ–∑.")
    print("DEBUG: –î—ñ–π—à–æ–≤ –¥–æ –ø–æ—á–∞—Ç–∫—É —Ü–∏–∫–ª—É")
    
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤
    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
    model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=4)
    if os.path.exists("models/best_model.pth"):
        model.load_state_dict(torch.load("models/best_model.pth", map_location=torch.device('cpu')))
        model.eval()
    
    while True:
        print("\n=== –ú–µ–Ω—é ===")
        print("1. –ù–∞—Ç—Ä–µ–Ω—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å")
        print("2. –ó—Ä–æ–±–∏—Ç–∏ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è")
        print("3. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö")
        print("4. –í–∏–π—Ç–∏")
        choice = input("–í–∏–±–µ—Ä–∏ –æ–ø—Ü—ñ—é (1-4): ")

        if choice == "1":
            print("\n–ü–æ—á–∏–Ω–∞—î–º–æ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
            train_model()
            print("–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            # –û–Ω–æ–≤–ª—é—î–º–æ –º–æ–¥–µ–ª—å –ø—ñ—Å–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
            model.load_state_dict(torch.load("models/best_model.pth", map_location=torch.device('cpu')))
            model.eval()
        elif choice == "2":
            if not os.path.exists("models/best_model.pth"):
                print("\n‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞: –ú–æ–¥–µ–ª—å —â–µ –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞. –°–ø–æ—á–∞—Ç–∫—É –≤–∏–±–µ—Ä—ñ—Ç—å –æ–ø—Ü—ñ—é 1 –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è.")
            else:
                text = input("\n–í–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó: ")
                label = predict_text(text, model, tokenizer)
                print(f"\nüìù –¢–µ–∫—Å—Ç: {text}")
                print(f"‚û°Ô∏è –ö–ª–∞—Å: {label}")
        elif choice == "3":
            evaluate_test_data()
        elif choice == "4":
            print("–î—è–∫—É—é –∑–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è ThreatTextAI. –î–æ –∑—É—Å—Ç—Ä—ñ—á—ñ!")
            sys.exit()
        else:
            print("–ù–µ–≤—ñ—Ä–Ω–∏–π –≤–∏–±—ñ—Ä. –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑.")

if __name__ == "__main__":
    main()